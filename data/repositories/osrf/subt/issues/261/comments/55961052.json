{"links": {"self": {"href": "data/repositories/osrf/subt/issues/261/comments/55961052.json"}, "html": {"href": "#!/osrf/subt/issues/261#comment-55961052"}}, "issue": {"links": {"self": {"href": "data/repositories/osrf/subt/issues/261.json"}}, "type": "issue", "id": 261, "repository": {"links": {"self": {"href": "data/repositories/osrf/subt.json"}, "html": {"href": "#!/osrf/subt"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3c95f6ad-c304-407c-b838-09597d836552}ts=2272898"}}, "type": "repository", "name": "subt", "full_name": "osrf/subt", "uuid": "{3c95f6ad-c304-407c-b838-09597d836552}"}, "title": "CloudSim stops sending some topics"}, "content": {"raw": "I am trying to confirm the hypothesis that the problem happens under heavy load. TL DR: the load must be really really heavy but I was able to reproduce it locally.\n\nOur solution contains 2 processes - first is a ros cpp node that subscribes to all topics we need and forwards all received data to the second process which is python implementation of our controller \\(which is completely ROS independent\\). On my notebook the ros node takes around 40% CPU and the python process takes around 300% CPU \\(I have total of 8 logical cores at 3.8Gz\\).\n\nIn order to simulate the problem I used taskset to move both processes \\(with all its threads\\) to a single CPU core. The python part contains some adaptation to load so the result was 40% for ros proxy and 60% for python controller. However, the controller was driving the robot around just fine.\n\nThen I reniced the ros proxy to 19 and only then the problems appeared. In order to better see what is going on, it is beneficial to enable ROS DEBUG logging \\(see [https://github.com/robotika/osgar/pull/303/commits](https://github.com/robotika/osgar/pull/303/commits)\\). Then I get logs of messages being dropped due to queues being full. The fastest topics go down first, like ie. clock, then imu etc.\n\nSo my hypothesis is that when cloudsim runs many simulations in parallel, the controllers get significantly less CPU then before when almost nothing has been running. It would be nice to check if this is indeed what is happening.", "markup": "markdown", "html": "<p>I am trying to confirm the hypothesis that the problem happens under heavy load. TL DR: the load must be really really heavy but I was able to reproduce it locally.</p>\n<p>Our solution contains 2 processes - first is a ros cpp node that subscribes to all topics we need and forwards all received data to the second process which is python implementation of our controller (which is completely ROS independent). On my notebook the ros node takes around 40% CPU and the python process takes around 300% CPU (I have total of 8 logical cores at 3.8Gz).</p>\n<p>In order to simulate the problem I used taskset to move both processes (with all its threads) to a single CPU core. The python part contains some adaptation to load so the result was 40% for ros proxy and 60% for python controller. However, the controller was driving the robot around just fine.</p>\n<p>Then I reniced the ros proxy to 19 and only then the problems appeared. In order to better see what is going on, it is beneficial to enable ROS DEBUG logging (see <a data-is-external-link=\"true\" href=\"https://github.com/robotika/osgar/pull/303/commits\" rel=\"nofollow\">https://github.com/robotika/osgar/pull/303/commits</a>). Then I get logs of messages being dropped due to queues being full. The fastest topics go down first, like ie. clock, then imu etc.</p>\n<p>So my hypothesis is that when cloudsim runs many simulations in parallel, the controllers get significantly less CPU then before when almost nothing has been running. It would be nice to check if this is indeed what is happening.</p>", "type": "rendered"}, "created_on": "2020-01-31T12:37:34.953181+00:00", "user": {"display_name": "Zbyn\u011bk Winkler", "uuid": "{d253a02a-aa23-4c28-9bf2-75863acb0ee0}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bd253a02a-aa23-4c28-9bf2-75863acb0ee0%7D"}, "html": {"href": "https://bitbucket.org/%7Bd253a02a-aa23-4c28-9bf2-75863acb0ee0%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/326a12c819c60ee18418b5d01000d03fd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsZW-1.png"}}, "nickname": "Zbyn\u011bk Winkler (robotika)", "type": "user", "account_id": "557058:a92b5a4f-5b91-4853-8dec-b918bd975e70"}, "updated_on": null, "type": "issue_comment", "id": 55961052}