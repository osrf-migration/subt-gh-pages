{"priority": "minor", "kind": "bug", "repository": {"links": {"self": {"href": "data/repositories/osrf/subt.json"}, "html": {"href": "#!/osrf/subt"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3c95f6ad-c304-407c-b838-09597d836552}ts=2272898"}}, "type": "repository", "name": "subt", "full_name": "osrf/subt", "uuid": "{3c95f6ad-c304-407c-b838-09597d836552}"}, "links": {"attachments": {"href": "data/repositories/osrf/subt/issues/300/attachments_page=1.json"}, "self": {"href": "data/repositories/osrf/subt/issues/300.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/osrf/subt/issues/300/watch"}, "comments": {"href": "data/repositories/osrf/subt/issues/300/comments_page=1.json"}, "html": {"href": "#!/osrf/subt/issues/300/running-into-max-depth-exceeded-error-with"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/osrf/subt/issues/300/vote"}}, "reporter": {"display_name": "Malcolm Stagg", "uuid": "{eee13832-fdd5-4196-aa05-6cfdb1118c65}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beee13832-fdd5-4196-aa05-6cfdb1118c65%7D"}, "html": {"href": "https://bitbucket.org/%7Beee13832-fdd5-4196-aa05-6cfdb1118c65%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/8c08ab97dc600bddad36e4a58f8cc5afd=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsMS-3.png"}}, "nickname": "malcolmst7", "type": "user", "account_id": "557058:08ef8b07-1500-4917-989c-89f91ce4beac"}, "title": "Running into \"max depth exceeded\" error with the current subt-virtual-testbed base image", "component": null, "votes": 2, "watches": 3, "content": {"raw": "This isn\u2019t really a major problem, I can workaround it, but in the most recent `osrf/subt-virtual-testbed` base image, I am running into \"max depth exceeded\" errors in my own Dockerfiles. It seems the fs layer count of the `subt-virtual-testbed` image is very close to Docker\u2019s maximum \\(which appears to be around 127\\). So when I add several additional fs layers, it runs into the limit.\r\n\r\nRunning `docker history osrf/subt-virtual-testbed:latest` I can see there are a lot of layers corresponding to `ign fuel download` commands.  These could probably be consolidated a bit more to avoid running close to this limit.\r\n\r\nIf anyone else runs into the same problem though, a fairly simple workaround is to run `docker-squash` on the `subt-virtual-testbed` image to flatten it before using it in my own files, something like:\r\n\r\n```\r\nsudo docker-squash osrf/subt-virtual-testbed:latest -t subt-virtual-testbed-flat:latest | docker load\r\n```\r\n\r\n\u200c", "markup": "markdown", "html": "<p>This isn\u2019t really a major problem, I can workaround it, but in the most recent <code>osrf/subt-virtual-testbed</code> base image, I am running into \"max depth exceeded\" errors in my own Dockerfiles. It seems the fs layer count of the <code>subt-virtual-testbed</code> image is very close to Docker\u2019s maximum (which appears to be around 127). So when I add several additional fs layers, it runs into the limit.</p>\n<p>Running <code>docker history osrf/subt-virtual-testbed:latest</code> I can see there are a lot of layers corresponding to <code>ign fuel download</code> commands.  These could probably be consolidated a bit more to avoid running close to this limit.</p>\n<p>If anyone else runs into the same problem though, a fairly simple workaround is to run <code>docker-squash</code> on the <code>subt-virtual-testbed</code> image to flatten it before using it in my own files, something like:</p>\n<div class=\"codehilite\"><pre><span></span>sudo docker-squash osrf/subt-virtual-testbed:latest -t subt-virtual-testbed-flat:latest | docker load\n</pre></div>\n\n\n<p>\u200c</p>", "type": "rendered"}, "assignee": null, "state": "resolved", "version": null, "edited_on": null, "created_on": "2019-12-22T10:17:35.379823+00:00", "milestone": null, "updated_on": "2020-03-27T03:37:20.563294+00:00", "type": "issue", "id": 300}