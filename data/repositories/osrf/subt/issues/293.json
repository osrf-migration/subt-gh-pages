{"priority": "major", "kind": "proposal", "repository": {"links": {"self": {"href": "data/repositories/osrf/subt.json"}, "html": {"href": "#!/osrf/subt"}, "avatar": {"href": "data/bytebucket.org/ravatar/{3c95f6ad-c304-407c-b838-09597d836552}ts=2272898"}}, "type": "repository", "name": "subt", "full_name": "osrf/subt", "uuid": "{3c95f6ad-c304-407c-b838-09597d836552}"}, "links": {"attachments": {"href": "data/repositories/osrf/subt/issues/293/attachments_page=1.json"}, "self": {"href": "data/repositories/osrf/subt/issues/293.json"}, "watch": {"href": "https://api.bitbucket.org/2.0/repositories/osrf/subt/issues/293/watch"}, "comments": {"href": "data/repositories/osrf/subt/issues/293/comments_page=1.json"}, "html": {"href": "#!/osrf/subt/issues/293/versatile-robot-configurations"}, "vote": {"href": "https://api.bitbucket.org/2.0/repositories/osrf/subt/issues/293/vote"}}, "reporter": {"display_name": "Martin Dlouhy", "uuid": "{27de76db-249c-44be-9eb8-91a3b17bf0d7}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B27de76db-249c-44be-9eb8-91a3b17bf0d7%7D"}, "html": {"href": "https://bitbucket.org/%7B27de76db-249c-44be-9eb8-91a3b17bf0d7%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/85a9b1d43839b393296feb3b35a2e577d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsMD-1.png"}}, "nickname": "robotikacz", "type": "user", "account_id": "557058:490c665b-b69c-40f3-80ea-64f20747efc4"}, "title": "Versatile Robot Configurations", "component": null, "votes": 0, "watches": 3, "content": {"raw": "Today is the deadline for the user model submission via pull-request for Urban Circuit, so this post is rather proposal for the next challenge.\r\n\r\nThe process adding new configuration is rather complex - here I would like to thank @{557058:14b7fd50-d65a-47a8-825c-fa89681d07bd}  for his help with our \\(\"robotika\"\\) pull request \\(it is not over yet\\). Actually all we wanted to do is to replace original HD camera in X2 config 4 \\(with lidar 30m\\) by RGBD in order to see small obstacles in front of the robot and distinguish ramps from obstacles. The PR is mainly copy & paste of parts we do not really understand \\(unfortunately there was no working example to start with, but this will surely change for Cave Circuit\\). Also we should not really get the attribution \\(#284\\), unless you count this process :wink:. Note, we gave up to repeat this process for X1 which could be more suitable for the subway environment \\(rails\\).\r\n\r\nSo that was the motivation - question is if this can be simplified? In particular if you are building configuration only from existing  \r\ncomponents \\(robot and sensors\\) and you only \"mount\" them together. The complex process can be reserved for new/non-existing robots and sensors. The configuration would be then like \"shopping list\" where you could choose from sensors and only specify placement. There could be even just few \"mounting positions\" like front, left, rear ... or just \\(x y z yaw pitch roll\\). There is no need to copy materials, worlds, models etc. This list would be input for \u201cgenerator\u201d which could create the complex configuration if that is the only way - or it could create it \u201con demand\u201d during start of the simulation. Is this feasible?", "markup": "markdown", "html": "<p>Today is the deadline for the user model submission via pull-request for Urban Circuit, so this post is rather proposal for the next challenge.</p>\n<p>The process adding new configuration is rather complex - here I would like to thank <span class=\"ap-mention\" data-atlassian-id=\"557058:14b7fd50-d65a-47a8-825c-fa89681d07bd\">@Arthur Schang</span>  for his help with our (\"robotika\") pull request (it is not over yet). Actually all we wanted to do is to replace original HD camera in X2 config 4 (with lidar 30m) by RGBD in order to see small obstacles in front of the robot and distinguish ramps from obstacles. The PR is mainly copy &amp; paste of parts we do not really understand (unfortunately there was no working example to start with, but this will surely change for Cave Circuit). Also we should not really get the attribution (<a href=\"#!/osrf/subt/issues/284/index-number-of-new-configuration\" rel=\"nofollow\" title=\"Index number of new configuration?\" class=\"ap-connect-link\"><s>#284</s></a>), unless you count this process <img class=\"emoji\" src=\"data/pf-emoji-service--cdn.us-east-1.prod.public.atl-paas.net/standard/551c9814-1d37-4573-819d-afab3afeaf32/48x48/1f609.png\" alt=\"\ud83d\ude09\" title=\":wink:\" data-emoji-short-name=\":wink:\" />. Note, we gave up to repeat this process for X1 which could be more suitable for the subway environment (rails).</p>\n<p>So that was the motivation - question is if this can be simplified? In particular if you are building configuration only from existing<br />\ncomponents (robot and sensors) and you only \"mount\" them together. The complex process can be reserved for new/non-existing robots and sensors. The configuration would be then like \"shopping list\" where you could choose from sensors and only specify placement. There could be even just few \"mounting positions\" like front, left, rear ... or just (x y z yaw pitch roll). There is no need to copy materials, worlds, models etc. This list would be input for \u201cgenerator\u201d which could create the complex configuration if that is the only way - or it could create it \u201con demand\u201d during start of the simulation. Is this feasible?</p>", "type": "rendered"}, "assignee": null, "state": "on hold", "version": null, "edited_on": null, "created_on": "2019-12-11T15:01:08.948315+00:00", "milestone": null, "updated_on": "2019-12-16T16:59:03.190804+00:00", "type": "issue", "id": 293}